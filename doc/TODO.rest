.. ; -*- mode:rst; -*-

====
TODO
====

Future improvements planned for XCVB.

See the first section, `Current Developments [V1]`_,
for what are hot topics you could be working on right now.

.. contents::
..
    1   Current Developments [V1]
    2   Roadmap [Done]
    3   Usability Issues [V1]
      3.1   Migration from ASDF [V1]
      3.2   In-image loading [V1]
      3.3   ASDF backend [V1]
      3.4   Centralized Dependency Declaration [V1]
      3.5   Exploded File Dependencies [V1]
      3.6   Lack of Manual [V1]
      3.7   Producing Executables [V3]
      3.8   Generalized Staged Images [Done]
      3.9   Command-line interface [Done]
      3.10  Configurability of the build image [Done]
      3.11  Conditional Build [Done]
    4   Features [V2]
      4.1   Improve Makefile backend [V2]
      4.2   Abstract Away Paths [V2]
      4.3   Initialization and Finalization [V2]
      4.4   Executables [V2]
      4.5   Tests [V2]
      4.6   Dependency grovelling [V2]
      4.7   Revert [V2]
      4.8   Bootstrap [V3]
      4.9   Same source, multiple compilers [V4]
      4.10  Correctly handling C libraries [V4]
      4.11  Dynamic compilation [V4]
      4.12  Bug hunting [V5]
    5   Ideas from jknight [V2]
    6   The semantics of dependencies [V2]
      6.1  Computed Lisp files [V2]
      6.2  Tests [V2]
      6.3  Crypto Check [V3]
      6.4  Template Instantiations [V5]
    7   Internals [V4]
      7.1  Type-Checking [V4]
      7.2  Error handling [V4]
    8   Higher-level description [V2]
      8.1  XCVB's Architecture
      8.2  Grains and Types
        8.2.1  Initial, Final and in-between
        8.2.2  Persistent vs Transient
        8.2.3  Intention vs Extension
        8.2.4  Names
        8.2.5  Generated "source" code
      8.3  Plans
        8.3.1  Build Graph
        8.3.2  Computations
        8.3.3  Actionable operations
        8.3.4  Complete plan
        8.3.5  Plan transformation
        8.3.6  Reference model
        8.3.7  Dependencies
      8.4  Operators
        8.4.1  Abstracting Operations
        8.4.2  Generating computation and hashes
        8.4.3  Graph building
      8.5  Notes
    9   Advanced Build Issues [V3]
      9.1   Read the classics [V3]
      9.2   distclc [V3]
      9.3   clcache [V3]
      9.4   XCVB as its own backend [V3]
      9.5   Push for better control of file source location [V3]
      9.6   Push for better control of in-file source location [V4]
      9.7   Push for more determinism in Lisp compilers [V5]
      9.8   Push for First-class PCLSRing in Lisp compilers [V5]
      9.9   Support dependencies for modules written in other languages [V4]
      9.10  Mixing and Matching compilers [V5]
      9.11  Constraint-based goal language [V6]
    10  A Real Module System [V3]
      10.1  Syntax Extensions [V3]
      10.2  Automatic Package management [V5]
      10.3  Better Namespace Management [V5]
      10.4  Hooks into the Module Naming Resolution [V5]
      10.5  Packaging and Distribution [V5]
      10.6  More bibliography [V5]


Current Developments [V1]
=========================

Following a complete rewrite the XCVB 0.3 series has been released in July 2009.
We've got a Makefile backend with which we can recompile XCVB itself,
and compile a number of free software Lisp libraries.

Here is the top of our TODO list at ITA:

 * Make XCVB fast on our large system, on which it currently builds an order of magnitude
   slower than the ASDF build, on a quad-core system.
   See `Enhancing Build Speed`_.

 * Move tests outside from the system itself - speed compile, etc.

 * Apply XCVB to some actual big projects at ITA.

   + Complete the EVAL-WHEN cleanup of ITA code.

   + Implement the removal of XCVB module statements, so (a copy of) a migrated
     system may easily be de-a2x'ed, leaving only the EVAL-WHEN and other fixes,
     that may be merged upstream before we are ready to get module statements
     themselves merged. (Note: a lot of those EVAL-WHEN bugs are indeed bugs
     even when compiling with ASDF, and will show in case an incremental compilation
     when some of the files are already compiled but others not.)

   + Collect differences on ITA library dependencies into diffs.
     Publish them in the XCVB releases/ directory.
     Send them to upstream maintainers.

 * Figure out the shortest path from here to providing incremental testing
   for unit-tests and regression scripts. What state needs to be maintained?

   + Test reports are file grains that depend on the properly compiled
     fasls or images that are being tested.

   + A test report is a file the first form of which is
     a simple SEXP to be read,
     following some standardized structure to specify overall success,
     status of individual tests (including error message, maybe
     information as to last success, etc.).

   + For the sake of interoperability, we may specify a translation
     from said S-Expression test result format to XML
     that complies with what JUnit expects.
     (Suggestion by Robert Goldman <rpgoldman@sift.info>)

   + In collaboration with folks from BBN, rpg's colleague John Maraist
     has built this capability into his NST test framework.
     This means that a large system with Java components can all be tested together.

   + From the test reports, a success witness (empty file) may be created
     on success.

   + The success witness fails to be created when the test wasn't a success,
     and the process returns with an error code for make to catch.

   + Preparing the makefile erases the success witnesses.

   + To evaluate the progress of tests, regressions, etc., said state can be
     registered in some test state maintenance server.

 * Warnings about undefined functions are currently quenched during file compilation.
   HOWEVER, we should record them on the, and reconcile them afterwards,
   before or after image creation. In other words, we must implement
   ``with-xcvb-compilation-unit`` in a way that actually defers warnings,
   rather than plainly drops them.

   + Good compilers generate conditions when a function is forward referenced;
     these conditions need to be handled in implementation-dependent way, and
     the symbol-name and package-name of the referenced symbols need to be
     dumped into a file ``.fref`` alongside the ``.fasl`` and ``.cfasl``
     as each file is compiled.

   + Previous solutions in single-image build systems such as ASDF involved
     ``with-compilation-unit`` and simple wrappers around it that defer the
     handling of some conditions until the end of the compilation unit.
     However, because we are specifically invalidating this assumption that
     everything is compiled in the same image, we need to instead persist
     forward reference information in files, and complete the final check
     for undefined functions after image-dumping. This check would be the
     first XCVB-managed unit-test; implementing it would be a good way to start
     moving existing unit tests into incremental management by XCVB
     -- the ultimate goal of migrating QRes to XCVB.

   + Basically, one would create a test target dependent on the final image
     that runs a function that collects all these forward references and makes sure
     that all the referenced functions are indeed defined and defined as functions
     (rather than as macro).

   + The check would issue precise error messages describing which file referenced which
     undefined function, or which file used a macro without depending on the file that
     defined the macro.


Other top TODO items that are not on ITA's critical path include the following,
in a random order. They would be ideal for a non-ITA hacker to tackle.

 * Instrument the driver to dump timing information about the build in some side files:
   how long did it take to build? to load each of the elements? to load all of them?
   to actually compile the file? to actually dump the file?

 * Have a dependency optimizer that starts from whatever is declared
   (initially, what asdf-dependency-grovel provides, or even a linear ASDF::TRAVERSE-al;
   in any case, a known-working order), and strip them to a minimum.
   For each dependency that isn't confirmed known-needed (starting from the last to the first),
   try recompiling without said dependency. If there was an error, it is definitely needed.
   If the FASL and CFASL are identical, it was definitely not needed. If there was no error but
   different output, then mark as known unknown (can be made known known by testing, if a test
   suite is available -- in a first pass, keep all the known unknown).
   Importantly, distinguish compile-depends-on, load-depends-on and even cload-depends-on
   (for loading the cfasl) - with the "does it error out" test only for loading.
   Once some known-needed dependencies of some file are determined, propagating this dependency to
   other files that depend on the former will of course be instrumental in avoiding pointless
   attempts at doing without said dependencies; which is why attempts should be queued in a
   "brings most information" order.

 * Support dependencies on things to be CL:REQUIRE'd.

 * Filter out :static-file from consideration by a2x -- or maybe not:
   hopefully, ASDF 1.364 will have saner component-relative-pathname methods that don't
   create crazy pathnames with dots in the name and a null type.

 * Extend the ``command-line-arguments`` library to allow for better self-documentation
   of option specifications with ``:documentation`` keyword arguments to options,
   that can be trivially used to generate help for command options and sub-command options
   (think about ``svn`` or ``git`` calling conventions).
   Maybe make that an extension to command-line-arguments, that itself uses
   a more general tool to display stuff on a terminal while respecting terminal width;
   or that actually outputs HTML and uses lynx -dump.
   Or that outputs HTML and invokes a browser.
   Use that to generate XCVB internal help.

 * When identifying a file dependency,
   make the distinction between ``:source``, ``:object`` or ``:file``
   orthogonal to that between ``:lisp``, ``:fasl``, ``:image`` or ``:data``.
   This is not trivial because this requires:

     + changing the dependency normalization algorithm,
       probably normalizing to ``(:lisp (:source "subdir/foo.lsp" :in "/fullname/bar"))`` and
       ``(:fasl (:object "subdir/foo.lx64fsl" :in "/fullname/bar"))``
       (and autodetecting the pathname type for FASLs from the target implementation).

     + updating the ``graph-for`` algorithm to deconstruct the new pattern.

     + updating the ``dependency-namestring`` algorithm to deconstruct the new pattern.

     + to make things error-proof, adding another layer of registration that ensures that
       an actual pathname is only used for one kind of abstract dependency pathname.

 * When a generated file is described in a ``build.xcvb``,
   have the file itself depend on ``build.xcvb``.
   This is one more reason to distinguish
   dependency on ``(:data (:source "foo/build.xcvb"))``
   from dependency on ``(:build "foo")``.

 * Also, in generated files, double-check that there isn't
   an intermediate build that short-circuits the name resolution.
   e.g. if ``foo/bar.lisp`` is generated from a build with fullname ``/quux``,
   then there must *not* a build with fullname ``/quux/foo`` that preempts that name;
   if there is, issue an error early and refuse to build.

 * Add support for in-image backend. See `In-image loading [V1]`_.
   This may or may not benefit from the following,
   by connecting a master Lisp process to a slave XCVB
   itself executing ``make``.

 * Implement a portable library for executing sub-programs
   with arbitrary output redirection, that does at least what
   ``asdf:run-shell-program`` does, but hopefully much more,
   like python's ``popen2.popen3`` or even like what SCSH provides.
   This feature will eventually be used by
   our standalone distributed build system.
   Stelian Ionescu is possibly working on such a library as part of IOLib,
   but would appreciate our giving him a good API.
   See also http://common-lisp.net/project/external-program/

 * Add support for arbitrary shell commands, including support for
   filename expansion in shell commands, etc., in ``string-escape.lisp``.
   May or may not benefit from the previous.

 * Figure out why the call of ``directory`` in ``find-build-files-under``
   is so slow (at least in SBCL), and find a pure-lisp alternative
   to spawning a shell that executes ``find(1)``.
   Xof suggests profiling the thing as it runs.
   I suggest properly extending IOLib or osicat to do the right thing.

 * In general, figure out what are the slow parts of XCVB, and optimize them.

 * Re-implement the ASDF backend, so ASDF users can use XCVB builds.
   See `ASDF backend [V1]`_

 * Make XCVB independent from ``cl-launch``
   by implementing the missing functionality
   (init forms, resume function,
   minimal shell wrapping and/or standalone images).

 * [Fixed in SBCL 1.0.31.3 - remove this note when 1.0.32 is released]
   Get SBCL bug 411925 https://bugs.launchpad.net/bugs/411925 fixed
   so making images from images should work.

 * Expand the migration code from ASDF. See `Migration from ASDF [V1]`_.

 * Have a test suite for XCVB that includes automated migration of some benchmark ASDF systems
   (e.g. historical tarballs of well-known systems?)

 * For a binary release, issue a standalone clisp binary?

 * Implement `Exploded File Dependencies [V1]`_ then `Centralized Dependency Declaration [V1]`_.

 * It is best if ``xcvb.mk`` should be systematically recomputed before any build.
   Ideally, it should also record enough information to invalidate things that are
   going to be built in a different way from before, even though their timestamps
   may now look correct. Once again, see `Exploded File Dependencies [V1]`_

 * For debugging purposes, the xcvb Makefile shows how to disable parallelism
   with ``make xcvb PARALLELIZE=``
   (where the default value of ``PARALLELIZE`` is ``-j``).
   Document that.

 * In some future, XCVB should control make itself, have a debug option,
   and drop you at the REPL of the failing Lisp file with useful restarts.
   Also, there is now a ``xcvb-driver:debugging`` primitive.
   Make it possible to easily re-invoke the failing command with debugging enabled;
   maybe ``xcvb.mk`` should always include a ${DEBUGGING} statement in its output?
   Or should the ``driver.lisp`` check for some environment variable (ugh)?

 * Starting whenever we have users who actually use XCVB to bootstrap XCVB,
   we'll want ``driver.lisp`` to provide backwards compatibility.
   i.e. we can no longer change the semantics of ``:compile-lisp``.
   Instead, we must keep the old ``:compile-lisp`` and possibly provide new versions
   under a different name, such as ``:compile-lisp/2``.

 * Have an extensive test-suite to run before any tarball is pushed to the release directory.

 * Have a test-suite that validates the release-tarball before to publish it.

 * Refactor the outdated ``test/mock/a/c/Makefile`` and the related builds into
   a Common Lisp equivalent of GNU hello. Move it outside of the XCVB tree.


Enhancing Build Speed
=====================

After our initial implementation of XCVB for QRes, it appears that
the size of QRes and the depth of the dependencies as used so far
lead to a build time that is an order of magnitude slower
than the serial build time with ASDF, on a quad-core machine.

  Profiling the build:
    To understand what is taking so long,
    which files are clogging the build,
    and how much more clever build strategies (see below) could help,
    we should profile the build.
    This is relatively straightforward:
    edit the xcvb/driver so it will save aside the time spent
    on loading and compiling the various files.
    Then write some programs to analyze the results,
    and compare how a different build strategy would help.

  Building with forks:
    Don't build with make, but by forking processes that cache a partial state of the image
    with various CFASLs being loaded so far.
    This may tremendously reduce the overhead currently due to loading CFASLs.
    The advantage is that it can easily be automated with relatively little code (1 week).
    However, because of the combinatorial explosion in which subset of the CFASLs is required
    for building which file, this may or may not help as much as we'd like;
    but how much this would help we can evaluate by profiling the build without having to code it.
    The disadvantage is that we will have to make fork work with CCL again
    (my previous patch to CCL has bitrotten and gbyers didn't like the idea;
    so that would be a few more days of work to get it up to date).

  Refactoring:
    Rearrange our code so that the really needed forms that everyone depends on
    do not come attached to other heavy code that isn't depended upon but slows down the build.
    This can be done manually or semi-automatically (see below).
    How much this may potentially help may be measured by decomposing the build in individual forms
    (as msteele did for QPX), recomputing the dependency graph, and analyzing the profiling of a
    build based on that.

  Moving tests out of the way:
    As a straightforward form of refactoring, we should move all the test files
    out of the main build into unit-test subsystems are lisp test scripts.
    This would both take a lot of pressure out of the build system,
    and be a good way to formalize a systematic way to relate source files and test files,
    e.g. by having unit-tests in a test/ directory with files named similarly to the tested file,
    as is done by other CL test systems.

  Distinguishing FOO-time dependencies:
    It is possible that the load-time dependencies of files are much smaller than their
    compile-time dependencies, and that the load-time dependencies of CFASL may be even smaller.
    There is one way to determine that automatically:
    systematically try to remove each dependency from each file, one at a time, and see whether it
    still compiles without error, if possible to the same output (now that SBCL has somewhat
    deterministic output), whether its fasl still loads without error,
    and whether its cfasl still loads without error.
    This can also be fully automated in a way that requires zero-maintenance afterwards
    and provides a "lint" tool for dependencies.

  Using SB-HEAPDUMP:
    Instead of relying on the slow-loading FASL and CFASL,
    use a more efficient method more akin to ``.o`` files.
    Such a method currently exists for SBCL: SB-HEAPDUMP.
    It doesn't currently exist for CCL but could conceivably be implemented
    following the same model.
    Modular chunks of dumped state could then be loaded more cheaply than FASLs
    without implying the combinatorial explosion of having to save or fork
    images for all possible partial load orders.
    However, in addition to requiring technology we don't have on the CCL side,
    it requires adherence to some package discipline we don't follow in QRes,
    and for which we have no enforcement tool yet.


Roadmap [Done]
==============

Improvements required for XCVB version 1 are marked [V1].
These correspond to a system suitable to automatically replace ASDF,
but otherwise without any extra feature besides
the enhanced robustness, maintainability and integration with ``make``.

Improvements required for XCVB version 2 are marked [V2].
These correspond to the "V" in XCVB: Verification.
Automated incremental testing, dependency groveling,
checksum verification, compartmentalized file trees, etc.

Improvements required for XCVB version 3 are marked [V3].
The goal is for XCVB to be able to build Lisp projects
all by itself, taking advantage of parallelism and distribution,
minimizing slow LOADs by forking (or dumping images?), etc.

Improvements required for XCVB version 4 are marked [V4].
The goal is for XCVB to become its own better building system,
able to build arbitrary Lisp or non-Lisp projects in a robust way,
with a distributed farm of machines able to identify objects
by a cryptographic checksum of
the precise source and compilation options used.

Improvements required for XCVB version 5 are marked [V5].
The goal is for XCVB to grow fancy features and heuristics
that demonstrate the advantages of a higher-level design.
Things go here that have really low priority.

As things get done, they should be moved
from the ``TODO`` document to the appropriate documentation
(at this moment, either ``README`` or ``INTERNALS``).


Usability Issues [V1]
=====================

This section describes usability bugs,
i.e. things that do not modify the deep semantic model of XCVB,
but are necessary to make it usable.


Migration from ASDF [V1]
------------------------

We can already do simple cases
with a proper command-line interface.
See the ``README.rest``.

Now, we need to handle more complex cases involving migrating
several ASDF systems to XCVB.
The converter could recursively migrate dependencies:
starting from specified systems,
transitively migrate asdf system dependencies,
stopping at given ones,
and skipping those already migrated unless explicitly requested.
Systems that rely on ASDF extensions such as
compile-time reading of data files,
dynamic creation of Lisp files
or conditional compilation
may have to be manually migrated and/or
their automatically migrated ``build.xcvb`` may have to be manually edited.
Some systems may also be merged together, as specified by the user.

Also, unmigration, stripping any generated module statement, should be supported.
So should be merging changes into previously manually-edited build.xcvb files.


In-image loading [V1]
---------------------

Provide support for XCVB to be able to handle
compiling and loading a system into the current Lisp image.

This support is to be provided by a small and simple build ``/xcvb/master``.

For better determinism, in-image loading will by default
delegate all compilation to some slave sub-process using the
best supported backend (which would probably be the make backend);
when done compiling, the slave would communicate to the master process
a list of files to load, which the master process would proceed to load indeed.

Optionally, the master would maintain a cryptographic hash-table
of modules already loaded, and the slave would avoid asking to load
previously-loaded files. Of course, in-image loading in general,
and this "optimization" in particular, are not guaranteed to work,
because the side-effects of loading a file can require pre-conditions
that are violated by the loading of previous versions of the software
and/or of other modules that modified the semantics of objects defined
in said previous versions.

Notable issues are when a variable that used to be special or constant
in a previous version is no more such in the newer version,
when the signature of a generic function is changed,
when some defstruct is modified while still in use,
when the helpers of some functions in an active stack frame are redefined,
when global variables were side-effected in a way that would have had to be undone
and/or redone to reflect the new image state,
etc.

Alternatively, modules could declare symbols to unintern,
packages to delete, hook functions to unregister,
sufficient to wipe away possibly incompatible former versions
and replace them with new ones.
Or some automated analysis and detection could take place to determine such.
XCVB could then automatically unintern symbols, and
delete or rename away packages that are to be reloaded.

Note that in-image loading is also necessary for extensions to XCVB itself,
whereby extensions are to be loaded in the current XCVB image.
So the X of XCVB is a lie until such feature is implemented.


ASDF backend [V1]
-----------------

It is understood that ASDF can never fully implement
all the features required for XCVB.
Nevertheless, we should in most cases be able to do
a good enough job that with some additional discipline,
a correct XCVB module should build with ASDF as a backend.

Alternatively, the `In-image loading [V1]`_ backend could be combined
with an ASDF extension that creates bridge systems,
so that ASDF may dynamically invoke XCVB when such systems
are to be compiled.

Add a test suite for the ASDF backend.


Centralized Dependency Declaration [V1]
---------------------------------------

Some users have requested the ability to declare dependencies of a Lisp module
from the ``build.xcvb`` file instead of inside the Lisp file itself.

A syntax extension allowing such feature (making XCVB more similar to ASDF)
would be welcome.

To be practical and not lead to everything depending on build.xcvb and having
to be rebuilt every single time any dependency changes, this feature should be
accompanied by the below feature on exploded file dependencies.


Exploded File Dependencies [V1]
-------------------------------

Another useful feature it to store the computation for each object file
in its own shell script that is only modified when the contents actually change.
The shell script is the first dependency of the target, and the ``Makefile`` rule
could look like that::

	obj/foo/bar.fasl: obj/foo/bar.fasl.sh obj/foo/pkg.cfasl obj/foo/mac.cfasl
		sh $<

Additionally, this script can contain dependency information on all the things that matter
yet that are not encoded in the timestamps used by make:
e.g. timestamp and/or md5sum of the Lisp implementation that was previously used,
values of critical shell environment variables, etc.
This could notably include information from ``SBCL_HOME`` or ``CCL_DIRECTORY``.

The script can also contain a debugging option, so that the user may easily debug
something that went wrong -- and the script would output an offer to call the script
with the debug flag when it detects that things went wrong.

Note however that for the purposes of bootstrapping a project
(which should only matters for XCVB itself, really),
we can't include any such dependency on things
that are outside the distributed sources.
Therefore it should be possible to disable this feature
at least for the dependencies of such project.


Lack of Manual [V1]
-------------------

Document all there is to know to use XCVB in README.rest.
If README grows too big, create a separate MANUAL.rest.

There should be both a tutorial and an API specification.

Document or automate away things such as:

  * What should be in the ``Makefile`` of a project that uses xcvb:

     + what Make variables to configure and how to configure them
       (much fewer now that ASDF is not needed anymore).

     + what Lisp variables to setup and how to set them up,
       especially when still using ASDF.

     + rules to make ``xcvb.mk`` itself (always make it). How to use it.

     + how to use CL-Launch to build an executable from a xcvb-produced image.

  * Provide a formal specification of the module syntax and the dependency syntax, with examples.



Producing Executables [V3]
--------------------------

Currently, ``cl-launch`` accepts an explicit initial image as input,
and this can be used in a ``Makefile``
to create an executable from an image produced by XCVB.

In a second time [V3], XCVB should be extended to directly support
all the relevant features from cl-launch.


Generalized Staged Images [Done]
--------------------------------

Instead of ad-hoc bootstrap images, provide a general mechanism
for building images used to build further images,
and use it for the initial image.

Done, needs to be documented.


Command-line interface [Done]
-----------------------------

It should be possible to invoke and control XCVB fully from the shell command line
(and/or from a carefully constructed ``Makefile``)
without the user having to edit a Lisp configuration file.
The XCVB command-line should obey the usual unix command interpreter syntax::

	xcvb {xcvb-options} {script {script-arguments}}

The command-line should allow to express all the common usage patterns.
These patterns will be discovered as we build V1 and V2.

Done, needs to be made self-documented,
and extended as more features become available.


Configurability of the build image [Done]
-----------------------------------------

The user needs to be able to specify files to be loaded
and/or forms to be evaluated in the initial build image.
Most notably he needs to be able to customize his ``asdf:*central-registry*``
and possibly proclaim the desired optimization settings.

Typically, this is done by a file called setup.lisp
loaded into the initial staged build image.

It's there already, but we need to document how this works.

For an example, see the Makefile ``test/mock/a/c/Makefile``,
or the Makefile of XCVB itself.


Conditional Build [Done]
------------------------

To be documented in INTERNALS.

XCVB supports conditional compilation of some files.

Previously, we supported conditional reading with ``#+`` and ``#-``
using the features from the target system,
like people currently do with ASDF.
Because the builder and buildee are separate,
this means that XCVB must somehow extract the features of the buildee
(by running the target lisp) before it reads any of the files.

However, that approach was a hack with several drawbacks:

  * It doesn't scale to larger builds
    where the same file would be compiled many times
    using different compilers and feature sets.

  * It prevents us from using our "normal" way of naming lisp files
    for the initial user-customization file from ``--setup``,
    because we need to load such file for any customization of ``*features*``,
    yet we currently need the target ``*features*`` before we may properly
    use ``#+`` while reading and interning build files during
    ``(search-search-path)``,
    as needs be done before we may resolve "normal" names.

XCVB has a syntactic construct to specify conditional dependencies.
mudballs had the following syntax:
``(:usocket (:for (:not (:lispworks))))`` to conditionalize ``:usocket``.
That didn't directly fit the XCVB model, and so we instead use:
``(:when (:featurep (:not :lispworks)) "usocket")``.
(Note that we could imaginably hack the reader
to have ``#+`` and ``#-`` expand to that,
but that would be a lot of pain for little gain).

By mandating such syntax and/or hacking the reader,
we may intern the build files before any customization of ``*features*``,
then resolve the name of the setup file,
use that file and acquire the target ``*features*``,
and finally process features during graph building.


Features [V2]
=============

This section describes features that have to be added to XCVB.
They modify the underlying build model.


Improve Makefile backend [V2]
-----------------------------

Create and document the following small features:

  * give user control as to where generated objects go vs source code.

  * use Makefile variables as path prefix for most everything?

  * use a map file that maps virtual names to path locations?
    This will be required in a distributed build, anyway!
    Use logical pathnames for that! Logical host XSRC: ?
    But then, we might need to include parts of portablish-pathnames
    with the driver...


Abstract Away Paths [V2]
------------------------

Have a datastructure for "string with substituted variables" (or shell or Make function calls?).

Be able to either dump a corresponding string (for writing Makefile),
or to expand into an actual string (for running the build).

Map actual paths to and from variablized strings, i.e. have
``${FOO}/bar/${GAH}`` in your path; it will search for files there,
and output ``${FOO}/bar/${GAH}/xcvb/build.xcvb``
in the ``Makefile`` (instead of the full expansion).


Initialization and Finalization [V2]
------------------------------------

Some code has to be run before and after file is compiled.

Before to compile a file, one may want to

  * change the readtable (or the reader)
  * set up some infrastructure (db connection)
  * initialize some meta-data tables

At the beginning of a file's compilation, one may want to

  * Insert compile-time or load-time form to be evaluated
    to dynamically initialize the module.

At the end of a file's compilation, one may want to

  * Insert compile-time or load-time form to be evaluated
    to dynamically finalize the module.

After the file is compiled, one may want to

  * save cross-reference data
  * register dynamic dependencies (i.e. "requires once-per-project instantiation of this form")
  * more generally update meta-data


Executables [V2]
----------------

When creating a standalone executable, some initializers and finalizers may have to be run as above.

If the executable needs a wrapping script, things get even trickier.

We may want to reuse cl-launch here, to leverage all the support already available.


Tests [V2]
----------

Test modules should be run when their dependencies have changed;
i.e. after they have been compiled into a FASL,
they should be loaded and create a report of whether the run was successful.
Reports can further be collected for statistics, etc.


Dependency grovelling [V2]
--------------------------

We may want to document how to extend asdf-dependency-grovel
when migrating systems from ASDF.

Actually, we might be interested in tweaking asdf-dependency-grovel
into some kind of xcvb-dependency-grovel
and possibly move all the groveling on the XCVB side,
taking a simple ASDF assumedly working serial compile-and-load plan
as the initial dependency map.

An XCVB dependency checker can detect unnecessary dependencies,
optionally remove them automatically.
With the help of some registry, it may even suggest
which missing dependencies should be added
-- and optionally automatically recompile after adding them.

For bonus points [V3], the groveler should know how to distinguish
between ``:compile-toplevel`` and ``:load-toplevel`` side-effects to
the evaluation environment.


Revert [V2]
-----------

We want a function to easily revert
the changes made by the ASDF to XCVB conversion,
so we may more easily clean up and experiment.


Bootstrap [V3]
--------------

We may want to fully migrate all the existing Lisp world,
*including* XCVB, from ASDF to XCVB.

The hardest part may well be extending and migrating asdf-dependency-grovel
(see above), but it may well be worth it.

We will want to have some non-invasive incremental strategy
to migrating all the existing ASDF projects,
and to integrate with some existing distribution mechanism
(clbuild).


Same source, multiple compilers [V4]
------------------------------------

We will want to combine as part of the same build multiple compilations
of the same source files using different compilers and/or compiler options.

For instance, we may compile some source optimized for speed,
and the same source with extra safety features and code coverage instrumentation.
The code coverage version would be used in tests that identify
which parts of the test suite exert which part of the code,
and the results can drive future incremental testing of the test suite.
Meanwhile, the speedy version also runs the test suite,
just to make sure the optimizations don't break anything,
and it also is made to pass a performance tests
that aren't relevant to the slow version.

Another use for multiple compiler options is
when compiling the same source for use in different contexts,
such as one that is optimized for speed with default CL promises
(i.e. no guaranteed proper tail calls),
whereas the other one guarantees proper tail calls,
maybe provides call/cc (and supports interoperability with programs that do use it),
maybe even provides serialization of continuations, etc.
The more options you support,
the higher the burden on the compiler to produce good code,
but the wider the settings in which your code might be useful.
A very same executable could thus contain multiple versions of a same function
compiled with different options, to be used in different contexts.


Correctly handling C libraries [V4]
-----------------------------------

While objects may have to be compiled one way to be dynamically loaded into Lisp,
they may have to be compiled another way to be statically linked into the Lisp image.
XCVB will eventually have to know both ways, and do the right thing.

For dynamic objects, it should be able to have them installed in a place that
the Lisp image can find them when it needs them later.

For static objects, it should be able to recompile the Lisp runtime to include them.
This will require some synchronization with CFFI.


Dynamic compilation [V4]
------------------------

XCVB should have a thin layer that enables to call it from an interactive environment,
and request the loading of some system.

The thin layer will collect the information about the running system
and about objects already loaded in it, as well as the additional systems required,
then invoke (with fork+exec) an XCVB process that will build any additional file
and print a form to be evaluated by the calling process so it may be suitably enhanced.


Bug hunting [V5]
----------------

XCVB should be able to track down all the source files
involved in a test and point the blame to all those changesets
in the version control system that affected said files,
barring other changesets.
Actually, this information can be used to accelerate binary search
in a bissect-based bug hunt.
In such a hunt, some components would be fetched from version control
and others be otherwise cast in stone or computed --
which is particularly useful when the test was written
after the bug was found rather than the bug being a regression,
or when several bugs were introduced in a series of changesets,
some of which having been found and fixed bug not others.


Ideas from jknight [V2]
=======================

Ideas from discussion w/ jknight:

 * allow python-like hierarchical installation paths instead of named build.xcvb
   (Isn't that already possible? Just have a top-level build.xcvb fullname'd "/" somewhere!)
   (The point was probably that we can avoid eager search if only we can agree on
   some naming hierarchy for both "module names" and filesystem relative paths.) [Done]

 * allow pre-built installation paths that are self-describing enough to make it work. [Done?]

 * extending XCVB: allow people to export a procedural interface as in "rebuild me"
   rather than only a declarative interface "conform to my crazy internal graph representation". [V2]
   (Note that if you're using the Makefile backend, you can just add rules to a Makefile
   that otherwise ``include``s the XCVB output.)

 * Makefile already doesn't like spaces in names (except implicit names from current path),
   so we must be using relative pathnames inside the Makefile by default. [Done]

 * allow xcvb.mk to be usable without the XCVB binary, for bootstrap purposes. [Done]

 * Must allow path-independent inclusion of foreign libraries (as -ljpeg in gcc)
   in portable xcvb.mk output [V2].

 * --object-directory=object option [Done]

 * Allow output to go in different directory from the source, with sensible defaults.
   For instance, with autotools, the output by default goes
   into the directory from which it is run. [V2]

 * option to only create relative pathname. [V2]

 * do away with all calls to truename. [Done]


The semantics of dependencies [V2]
==================================

Computed Lisp files [V2]
------------------------

Allow source files to be dynamically computed,
including the computation of its dependencies.

For the Make backend, this means that ``xcvb`` and ``make``
shall be called recursively called by the rule for the object target
after the Lisp file has been created.

For the independent backend, this means that the dependency graph
can grow new nodes and arcs as some files are discovered.


Tests [V2]
----------

XCVB should also have an interface to specially run (or skip) tests.

Tests don't just output a summary,
they also have a status that affects the build.
For instance a test that runs to completion
and successfully creates a valid report
may detect issues that flag the build as a whole as invalid.

XCVB should be able to thus synthesize and associate diagnostics to the overall built.


Crypto Check [V3]
-----------------

An important precondition to deterministic compilation is that
input files should not be modified in the middle of a compilation run.
XCVB should have a safe mode (enabled by default)
to check the cryptographic checksums at the beginning and end
of each transaction, and abort the transaction removing dubious object files
if anything has changed between the beginning and end of a command.

Here, transaction means anything that commits any object file to cache,
any metadata to some registry, etc.

For instance, if you're compiling file foo.lisp that depends on bar.lisp
to create foo.fasl and foo.cfasl, with some additional code coverage instrumentation,
and dependency detection that gets registered in a side cache,
then record the checksums of foo.lisp and bar.lisp before you compile,
double check that they didn't change afterwards, if they did,
then remove foo.fasl and omit to update the cache.
The check before running a command may or may not be omitted
if the file has already been checksummed during the current run,
the previous checksum being used;
or the checksum may be eagerly re-checked at every command.
In either case, it should always be checked after the command.

If checking checksum at every command is too time consuming, then there is the option
of only doing it at the beginning and end of the overall compilation,
but then any update of global caches should have the same granularity.
For a distributed build, definitely check before and after every command.


Template Instantiations [V5]
----------------------------

One interesting type of dependencies is template instantiation.
Some libraries may provide a family of algorithms
that are parametrized by various types or values,
the semantics of the algorithm being fully encapsulated
in the data of the library and the instantiation parameters.
The template for these algorithms must be instantiated
for a given set of parameters before it may be used,
yet this instantiation is costly enough in time and/or memory
that you want it to be done only once over the whole project.

We'll want XCVB to be able to track down such template instantiations.
One way of course is to have the user do it manually,
with one of the declared dependencies of a module being
something that instantiates the library.
This works if such templated libraries are few and far between.
Another way that scales to massive use of such libraries
is that the compilation process would automatically detect
the need for such instantiations,
and include them as additional project dependencies
as the need for such appears.


Internals [V4]
==============

Type-Checking [V4]
------------------

XCVB uses some poor-man's mechanism for writing in a decentralized way
code that can handle "little languages" that are thus easy to extend: 
``define-simple-dispatcher``.

At some point we might probably want to systematize
the use of these "little languages",
aka Abstract Data Types, and provide a way to type-check our code,
automatically verify that we're handling all the cases as we extend them,
give meaningful feedback for errors in user-provided input, etc.


Error handling [V4]
-------------------

We should refactor all error throwing with a call to simply-error,
using a condition defined specifically for that error.

We should also provide a nicer way of presenting errors to the end-user.
Maybe there should also be some library for that.



Higher-level description [V2]
=============================

At some point, this section should be updated, cleaned up
and moved to the INTERNALS.rest document.


XCVB's Architecture
-------------------

It's OK that we started with hand-coding the behaviour of XCVB in Lisp
but eventually, we should have a domain-specific language to describe
the structure of the dependency graph and the operations used to build it.

For XCVB version 1, we want to cleanup the internals. [Done]

For XCVB version 2, we want to have a sensible basic design
for arbitrary Lisp code.

For XCVB version 4, we want to have a fully generalized design
that can handle arbitrary operations used to build projects
using any kind of programming language or compiler, not just Lisp.

For the sake of avoiding ambiguity and starting from existing knowledge,
we'll try to reuse the vocabulary defined in MIT AITR-874
to describe the concepts at hand.


Grains and Types
----------------

*Grains* are the units of data that the build deals with.

Grains come in many *types*
themselves hierarchically organized in subtypes and supertypes.
Main types include files and running processes;
subtypes of files include Lisp source files, C source and header files,
shell scripts, python scripts or perl scripts,
ReST documents, FASL files (that come in as many variants
as there are combinations of Lisp implementations and various options),
linker object files (for many architectures),
executable files (for as many architectures),
test report files, etc.
Types of processes include Lisp compilation processes,
C compilation processes, etc.


Initial, Final and in-between
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Some grains are the inputs of the overall build, they are the *initial* grains.
They include the *source* code and data
(usually kept under revision control and otherwise part of the source archive),
user-specified *configuration* (edited by users to fit their local configuration),
and any file (such as a compiler) or process (some daemon) in the running *environment*
that is used during the build.
Anything else is a *derived* grain.

Some grains are the outputs of the overall build, they are the *final* grains.
They are anything sought for by the user,
usually deliverable files needed for some software installation.

Some grains may be both initial and final,
for instance data files that are copied over as is
from the source archive to the final installation.
Some grains are neither initial nor final, they are called *intermediate* grains,
and are usually thrown away after the build.

For *bootstrapping* purposes, the content of a final grain
is sometimes copied into what will be a source grain in future sessions.
Within a given build session, though, we will distinguish
the initial grain
(that may be the copy of a final grain from a previous session)
from the final grain
(that may be copied as an initial grain for a next session).


Persistent vs Transient
^^^^^^^^^^^^^^^^^^^^^^^

A *session* is a given run of XCVB.

Grains are *persistent* if their contents remain accessible from session to session.
They are stored on disk or some other permanent media.
Typically, persistent grains are files.
Persistent grains cannot spontaneously compute.

Grains are *transient* when their contents disappear between sessions.
Typically, transient grains are processes.
Transient grains do the computations.
They can transform inputs into outputs, and in between maintain active state.
They often are born and die within a session,
and may not be trusted to survive until a next session
(although if the build is used to monitoring updates to a live robust system,
they may well be).


Intention vs Extension
^^^^^^^^^^^^^^^^^^^^^^

We must distinguish file path from file contents,
process id and process state.

File *contents* are pure extensional data,
while file *names* are intentional anchors.
Similarly, running *processes* are the intentional agents,
whereas *process states* are the extensional states.

In a given *session*,
the mapping of name (intention) to contents (extension)
is assumed to not change.
Otherwise, an error condition is detected,
and the build may be aborted or restarted as a new session.
In a given session,
it may thus be assumed that a file behaves
like persistent pure functional data,
deterministically yielding the same contents every time it is read.

On the other hand,
the mapping from processes (intention) to process states (extension)
is likely to change a lot during a session
(and a fortiori between sessions).
The computation that happens in a given process consumes
its input state that is lost as it produce its output state.
Process state is thus behaves like a linear pure functional data.
Processes may be created with an birth state,
or die and cease to have a state.

Process state is often considered up to some gross equivalence
that neglects details such as process id, etc.
If you may neglect a small driver that forks the processes
and executes requested tasks,
or dumps images and resumes from them,
then you may be able to explicitly duplicate the state of a running process.
So as to be able to reinstate a desired state
on another machine or in another session,
the build needs to be able to reconstruct such state
from persistent data (e.g. by dumping an image),
up to the desired equivalence.


Names
^^^^^

A grain can have many names.
Its *fullname* is how it is named in the build graph.
A file's *path* indicates where in the filesystem the grain is stored.
Its *contenthash* is a cryptographic checksum of its contents.
Its *buildhash* is a cryptographic checksum
of the abstract computation used to compute the contents of the file
and of the buildhashes of any inputs used during the computation.

A cache mapping buildhash to contenthash and contenthash to contents
can help save actual computation time in repeated or distributed builds.


Generated "source" code
^^^^^^^^^^^^^^^^^^^^^^^

Generated code files count as derived grains, not source,
since they need not be part of the source archive
and are not checked in to revision control system
(unless they are indeed bootstrapped,
in which case the derived final file of a build
may be initial source file for the next).

They may make the build more complex in that
the build needs to know the associated dependencies
before it may plan how to build the derived grains,
yet may not be able to know these dependencies
before the Lisp file is generated.

In simple cases, the dependencies can be identified
before the file is generated,
as special off-file declarations in the generating source code.

In other cases, the build system may have to update
its build graph after the file is computed,
possibly doing a recursive call to the main build entry point.


Plans
-----

Build Graph
^^^^^^^^^^^

The plan is a build graph
that contains nodes that represent the intensional grains,
and nodes that represent the intensional computations
that will derive output grains from input grains,
from the initial ones up to the final ones.

As the builder executes the plan,
it computes the extensions of derived grains
from the extensions of former grains.

At the beginning of a session,
only the initial extensions are available.
At the end of a session,
the final extensions are computed.

The plan is static if it doesn't need to be updated
based on the extension of any derived grain.
The plan is dynamic if it new nodes need to be created
during a given session.


Computations
^^^^^^^^^^^^

Computations are nodes in the build graph,
that join together a set of input grains to a set of the output grains.

A computation node represents an actual computation whereby the output grains
can be computed from the input grains when the latter are available.

The computation may involve creating processes or talking to existing processes;
these processes will change state, including being born and dying,
as they run the specified commands,
creating output grains as they consume input grains.

For caching purposes, a computation also specifies how to compute a buildhash
identifying each of the outputs of the operation
from the buildhashes of inputs.


Actionable operations
^^^^^^^^^^^^^^^^^^^^^

In a given backend (i.e. ``Makefile``, ASDF, etc.),
not all operations are permitted.
For instance with make, you can't duplicate a process state with fork,
whereas you could with a future native backend.
Additionally, some Lisp compilers have operations that other compilers don't.
For instance, you can't load then dump --
instead you link with a special process.
An operation that can actually be executed is called *actionable*.

And so whether operations are decomposed into basic elements
or grouped in actionable wholes depends on the specific target.
Also, multiple operations may lead to the "same" outcome
up to the desired equivalence, and operations may be combined
in different ways.
Some combinations may be preferred to others,
especially if the some are valid operations on the target
whereas the others are not,
but also if some operations are reputedly slow
whereas others are expected to be fast.


Complete plan
^^^^^^^^^^^^^

In a complete plan, all operations are actionable.
Moreover, initial grains are never the output parameter of an operation,
and derived grains appear as the output parameter of an operation
exactly once in the build graph.


Plan transformation
^^^^^^^^^^^^^^^^^^^

From the module declarations, a model may be constructed
of which modules contain compile-time or load-time references
to which other modules,
and otherwise depends on which modules at build-time, etc.
This reference model constitutes a build graph,
but may not be an actionable build graph,
and may notably include intermediate grains
representing process states that may be not be reachable
in the specific target environment
that the build session will take place in.

Thus, the build system may have to transform its plan
both for the purpose of correctness and
for purpose of performance optimization.
A build session with start by computing the reference model
from the extension of the initial grains,
and from the build request,
then apply configuration-dependent transformations
to that plan to create a complete plan.


Reference model
^^^^^^^^^^^^^^^

We possibly may want to fully distinguish the reference model
as something distinct from a build graph, just like the AITR-874 author.
Then we could handle reference classes such as:

  * ``(:package-ref A B)`` - A uses a package defined in B (before to either compile or load A, load B).
  * ``(:macro-calls A B)`` - A uses a (reader)macro in B (before to compile A, load B).
  * ``(:calls A B)`` - code in A calls code in B (before you run code in A, load B).
  * ``(:setup-calls A B)`` - while loading A there are calls to code in B (load B before you load A).

Note that the current XCVB model of ``:depends``, ``:load-depends``, ``:compile-depends``
corresponds loosely to ``:package-ref``, ``:setup-calls``, ``:macro-calls``.
We may want to add a ``:run-depends`` to add the functionality of ``:calls``.


Dependencies
^^^^^^^^^^^^

The *declared* dependencies of a node
(or declared inputs of an operation)
are computed by the operator that creates the operation node,
and include all the grains that must be available
before the operation may be computed.
They are established at the beginning of the session
at the time the actionable plan is created,
and do not change for a static plan,
but may be updated for a dynamic plan,
in which case an operation that will update the dependencies
might itself be required as part of the plan
before the operation may be computed.

The *effective* dependencies of a node
(or effective inputs of an operation)
include any grains that were actually consulted in computing the operation.
In a static build, these effective dependencies
will be the same as the declared dependencies.
In a dynamic build, which dependencies were or weren't included
may sometimes be discovered only after the fact.
If they are found to contain grains that weren't available,
a condition is raised, and
the build session may be aborted,
or the required grains may be computed
before the operation may be restarted.

Note that when an object file itself hasn't changed as a result of a computation,
but one its dependencies (or the list of dependencies itself) has changed,
then one may have to recompile all files that depend on it.
This is taken into account by digesting not just the direct dependencies,
all the transitive dependencies loaded before the computation.
And so, if building a propagation network for recompilation,
the list of dependencies itself is to be part of
the network that triggers updates to a compilation,
not just the individual dependencies listed.


Operators
---------

Abstracting Operations
^^^^^^^^^^^^^^^^^^^^^^

*operators* are methods that create concrete operations
out of various parameters.

Parameters may include input grains, output grains,
options (which compiler/flags to use), etc.

Note however, that the inputs and outputs
of one of the operations created by an operator
need not be those given as parameter by the operator.
For instance, an operator may create intermediate grains,
add detected dependencies, recurse by calling other operators, etc.
(Operators correspond loosely to what AITR-874 calls
request-handlers and reference-handlers,
or to what ASDF calls operations).

A same grain can be used as the parameter to multiple operations,
or to the same operator in multiple instances with different other parameters.
For instance, a file may be both compiled
and processed for documentation extraction.
Or it may be compiled for speed in one case,
compiled for code coverage in another case,
and compiled with serializable continuations in a third case.


Generating computation and hashes
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The computation, the static buildhash,
and the algorithm to compute the dynamic buildhash
may all be obtained from the same specification
of the relationship between outputs and inputs,
at the time the operator is instantiated.

Say the operation has some specification like::

  (:compile-lisp :loading (fasl1 fasl2)
		 :source lisp3 :target fasl3
		 :lisp-compiler image4 :options (o5 o6 o7))

Then the evaluator would invoke the specified Lisp image
with the proper options to load the specified fasls
and compile the source file into the target fasl.

The direct hash of a grain would be a cryptographic hash of
its specification (type and module name)
followed by the hash of its file contents
(or for a process,
the hashes of the binary images and configuration files used
to start the daemon).

The static buildhash of each output grain
can be obtained in advance of any computation
with a cryptographic hash of the concatenation of the specification,
something that identifies which output is considered
(say ``"(1)"`` for the first output,
or ``"(2 3)"`` for the third file in the second list of outputs,
or just the output module name),
and the successive static buildhashes of each of the inputs,
with the static buildhash of an initial grain being its direct hash.

The dynamic buildhash of each output would be computed in a similar way
right before (for a static computation)
or right after (for a dynamic computation)
the computation, by hashing the concatenation of the specification,
of the output identifier, and the successive direct hashes
of each declared input (for a static build)
or effective input (for a dynamic build).

The hashing algorithm used for all hashing by XCVB will be
a Tiger Tree Hash (TTH).

Hashes can be used to index a cache of already computed objects.
Static builds with only static computations
may use the static buildhash to index objects in the cache
in advance of any computation --
and by looking for final objects directly at the top of the graph
skipping unneeded intermediate grains.
Dynamic builds or builds with dynamic computations
must use dynamic buildhash to index objects in the cache
and must rebuild all grains from the ground up.
Builds with both static and dynamic elements are conceivable.


Graph building
^^^^^^^^^^^^^^

A build starts with an initial request:
an operator is called with a set of input parameters.


Notes
-----

To preserve incremental compilation with a central dependency declaration,
you could explode the central declaration.
Each files at the time
that you initialize when creating the ``xcvb.mk``
and update (if needed) each time you re-compile a file.
Each compiled file would have a corresponding dependencies file
caching which dependencies were used during the compilation of it,
stored in the ``obj/`` directory and updated when it changed. Lots of infrastructure, but doable.



Advanced Build Issues [V3]
==========================

Read the classics [V3]
----------------------

As we try to get XCVB to rival with existing build systems,
we may want to cover our bases and see what previous systems
did right and what they did wrong.

Rainer Joswig on #lisp suggested:
'BUILD: A tool for maintaining consistency in modular systems'
by Richard Elliot Robbins, 1985.
ftp://publications.ai.mit.edu/ai-publications/pdf/AITR-874.pdf
The build system described takes an interesting declarative approach:
the system builds an abstract model of the modules in terms
of grains having various kinds of directed reference relationships as
in ``(:macros-calls foo bar)``.
The task graph to fulfill a build request is automatically deduced
from the reference model and various request-handlers
(pre and post reference handling) and reference-handlers
that propagate the information along the nodes.

See also:

        * GNU Make http://www.gnu.org/software/make/
	* OMake http://omake.metaprl.org/index.html
	* CMake http://www.cmake.org/
        * Haskell Cabal http://www.haskell.org/cabal/
        * Boost Jam http://www.boost.org/doc/tools/jam/index.html
	* SCons http://www.scons.org/

distclc [V3]
------------

The first step towards distributed builds is to plug into the usual ``Makefile``, etc.,
mechanisms, only adding an automated manager for distributed compilation through
a farm of available hosts, just like ``distcc`` does for C compilation.

``distclc`` should be written on top of Erlang-in-Lisp.


clcache [V3]
------------

The second step towards distributed builds is to have an automated
(distributed) cache of compiled objects, just like ``ccache`` does for C compilation.

Interestingly, to do it properly, we index grains by a buildhash
that summarizes all the input used to build the grain, including
type of the grain, command used, contents of the source files,
binaries used to run the compilation, etc.

To achieve that in a semi-automatic way, we may architect the operations
used to build grains in an I/O-summarizing monad that identifies then
summarizes inputs and outputs of the operations --
which monad can itself be decomposed in terms of input-identifying
and output-identifying monads, etc.
In a Haskell world, the monad would annotate the type of each
of the many intermediate functions involved.


XCVB as its own backend [V3]
----------------------------

Eventually, we want to be able to take over the Lisp build from Make,
so as to achieve things that Make can't do.

This can be done after we have ``distclc`` and ``clcache``,
by evolving the result to the point that we don't need Make.


Push for better control of file source location [V3]
----------------------------------------------------

When doing a distributed build,
of course the actual pathname of the file being compiled or loaded
will be different from the virtual name of the module being compiled or loaded.

For instance, when asking ``distclc`` to compile
module ``foo/bar/baz.lisp`` under directory ``/home/fare/src/``
which as a dependency loads ``quux.fasl``,
``distclc`` may actually create a temporary file
``12345.lisp`` where ``12345`` is the hash of ``baz.lisp``
under directory ``/tmp/distclc/``
and reuse ``67890.fasl`` from ``/var/cache/clcache/6/7/``
where ``67890`` is the hash of ``quux.fasl``.

Yet when associating source location information to functions being compiled,
XCVB needs be able to tell the underlying Lisp compiler that it should be
using the virtual location foo/bar/baz.lisp (and foo/bar/quux.lisp),
and additionally identify the hash of the file's contents
and possibly its revision in the version control system.

Of course, logical pathnames as defined by the CLHS are about unusable.
So offer to standardize something different for those virtual paths,
and the way that SLIME and/or the builtin debugger with interpret those paths.

jsnell suggests to look at what SLIME does -- presumably (for SBCL)
ask for extra information to be stored in the debug info with
a non-standard with-compilation-unit keyword. OR one might be able to do
sneaky stuff with logical-pathname-translations: ask to ``COMPILE-FILE``
some logical-pathname for which an ad-hoc translation was created.


Push for better control of in-file source location [V4]
-------------------------------------------------------

A related problem is in-file source location.

When using a syntactic front-end that generates Common Lisp code
from a different dialect or language
(say, a variant that supports hygienic macros,
or a Haskell to Lisp compiler),
the precise in-file location of a source statement that CL compiles
is not at all the same as the one that matters for the debugger
to location the actual source code.

For instance, one could provide hygienic macros through a form
``WITH-HYGIENIC-MACROS`` that does the necessary whole-program
identifier tracking. This would make a typical CL source location
tracker that only remembers the enclosing toplevel form wholly useless.

The PLT Scheme system has a good source tracking facility
that we may want to reuse of get inspiration from.
Even the C preprocessor has the crude line identification:
``# 123 "baz.h" 2 3 4``

For SBCL, ask jsnell, tcr, nyef: the preprocessed file could expand to
things like ``#.(preprocessed-form 345)`` where the ``(preprocessed-form ...)``
function would return expanded forms and subforms that each (as applicable)
already have source locations associated through something like::

  (setf (gethash EXPANDEDFORM *some-source-location-hash*)
        ORIGINAL-SOURCE-LOCATION)


Push for more determinism in Lisp compilers [V5]
------------------------------------------------

We should encourage implementers of Lisp compilers
to offer as an option (or even the default)
to have as much determinism as possible in the compile of files.

If to avoid collisions these compilers require that
a pseudo-random number generator be initialized to different values
for each file being compiled,
then offer to initialize it based on the buildhash
for the current compilation
(with an override to a previous buildhash offered for debugging purposes).

Try to standardize an interface to deterministically initialize the PRNGs
and deterministically add noise to them, based on arbitrary initial seed data.

Maybe also standardize some strong cryptographic hash algorithms
and algorithm generators for arbitrary Lisp data,
as are used by clcache.


Push for First-class PCLSRing in Lisp compilers [V5]
----------------------------------------------------

To support single-stepping and safe concurrency
in arbitrary extensions to the base language,
it may be crucial to push a meta-level protocol for first-class PCLSRing
whereby writers of language extensions and applications
can specify the atomicity of their operations
in a way that will be compiled efficiently,
yet will guarantee that synchronization happens correctly
when interrupting a program.


Support dependencies for modules written in other languages [V4]
----------------------------------------------------------------

If XCVB is to become a general build tool,
it needs to be made aware of dependencies for projects written in other languages.
This includes using output of ``gcc -MM``, and other dependency generators.


Mixing and Matching compilers [V5]
----------------------------------

A given project may contain files written in many languages,
including but not limited to Common Lisp and C.
Additionally, there may be various different variants of FFI
to be used to interface modules written in different languages,
depending on the specific compiler and compiler options used.

For instance, interfacing code compiled by a given Scheme compiler
with given options will differ from interfacing with the same
code compiled by a different compiler, or even with code compiled
by same compiler with different options.
Yet, for whatever reasons, a given project might want to mix and match
modules written in different languages.

XCVB might grow some generic protocol to describe the steps required to
interface something to something else.


Constraint-based goal language [V6]
-----------------------------------

The build language of XCVB could in the most general case be
some constraint declaration language, and XCVB would use a constraint solver,
whereby you want to build a running system that has these final properties,
starting from an existing running system that has these initial properties.
XCVB could detect conformance of the specification with various known subsets
of the language that keep the constraint satisfaction easy.


A Real Module System [V3]
=========================

Up to version 4, XCVB can be seen as the bottom half of a real module system.
But hopefully we can build a real full-fledged module system on top of XCVB,
including syntax extensions and namespace management.


Syntax Extensions [V3]
----------------------

Because modules are compiled in a separate way that shields them
from unwanted compile-time side-effects necessary to build other modules,
it immediately becomes possible for a module to have a compile-time dependency
on a module that modifies the syntax of Common-Lisp by introducing arbitrary
macros and reader-macros.

We may generalize this by having XCVB manage an explicit override of the reader
used to compile a given module.

To preserve debuggability, this requires extension to existing compilers
so they provide better control of in-file source location [V4].


Automatic Package management [V5]
---------------------------------

Defpackage statements are a notorious pain to maintain in Lisp.
At the same time they need to be all setup in advance of the rest of the compilation.

A layer on top of XCVB could help manage packages dynamically,
by allowing to associate a package with a module, itself made of many submodules.
An initial simple ``defpackage`` form would be supplied by the user;
what the module actually ``export``'s (or even ``import``'s) could be dynamically inferred
from the compilation of the module (and all its submodules),
with the final ``defpackage`` being created automatically from this inferrence.

Recompilation might be required if the ``defpackage``'s imports have changed
since it was last inferred, or it could just be an error.

All users of the module would only see the final stable ``defpackage``,
and have to be recompiled when said ``defpackage`` changes.

Finally, this could serve as the basis for dumping
package-based partial heap dumps with ``SB-HEAPDUMP``
instead of using FASLs.


Better Namespace Management [V5]
--------------------------------

Packages are not the be-all end-all of namespace management.
Actually, they are a very midesigned antiquated hack from the 1970's
that has long overlived its expiry date.
Many much better namespace management systems have been created
since the 1980's for many Lisp dialects and other languages.
Even for Common-Lisp, cheap yet better replacement exists, Lexicons.

We may want to layer on top of XCVB
an syntactic extension to Common Lisp that properly handles namespaces.
(See BSDF?)

For instance, we might reuse concepts and even code from the PLT Scheme system,
both regarding their module system and their unit system.
A key to doing it properly is to have already solved the syntax extension issues
and the macro hygiene problem (see above).
But we can decouple the source-level debugging issue as an addendum to the
the being able to do it at all issue.

Don't miss this important bibliography:
  http://readscheme.org/modules/

Taylor Campbell on the irc.openprojects.net ``#scheme`` channel gave the following piece of advice.
Personally I think that it would be easiest to use Scheme48's module system for that,
but what I'd care most about is
(1) that you separate phases sensibly, and
(2) that you provide working hygiene.
See Flatt, 'Composable and Compilable Macros', 2002.
http://www.cs.utah.edu/plt/publications/macromod.pdf
(The R6RS's library system emphatically got phase separation wrong.
Don't repeat their mistake.)


Hooks into the Module Naming Resolution [V5]
--------------------------------------------

So as to support compilation of a project that spans over multiple builds,
a module naming system was implemented.

When a module is not found, a hook function may be called,
that allows for arbitrary computed modules, most notably including
modules automatically downloaded and installed on demand from the internet.


Packaging and Distribution [V5]
-------------------------------

At some point in a relatively distant future,
we may want to extend XCVB to handle
the automatic packaging and distribution of Lisp-based projects.

See ASDF-INSTALL, clbuild, etc.

See Haskell Hackage, Caml Hump,
PLaneT, Chicken eggs,
Ruby gems, Python eggs, Java beans, etc.

When extending the system to include the management of packages for distribution,
be sure that you play well with whichever Operating System's packaging software:
http://www.b-list.org/weblog/2008/dec/14/packaging/

See also on other CL forums if anything serious is brewing.


More bibliography [V5]
----------------------

http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=138664
