.. ; -*- mode:rst; -*-

====
TODO
====

Future improvements planned for XCVB.

.. contents::
..
    1   Current Developments
    2   Roadmap [V1]
    3   Usability Issues [V1]
      3.1  Lack of Manual [V1]
      3.2  Migration from ASDF [V1]
      3.3  Configurability of the build image [V1]
      3.4  In-image loading [V1]
      3.5  ASDF backend [V1]
      3.6  Conditional Build [V1]
      3.7  Generalized Staged Images [V2]
      3.8  Command-line interface [V3]
    4   Features [V1]
      4.1   Multiple BUILD.lisp files [V1]
      4.2   Improve Makefile backend [V2]
      4.3   Abstract Away Paths [V2]
      4.4   Initialization and Finalization [V2]
      4.5   Executables [V2]
      4.6   Tests [V2]
      4.7   Dependency grovelling [V2]
      4.8   Revert [V2]
      4.9   Bootstrap [V3]
      4.10  Same source, multiple compilers [V4]
      4.11  Correctly handling C libraries [V4]
      4.12  Dynamic compilation [V4]
      4.13  Bug hunting [V5]
    5   Ideas from jknight
    6   The semantics of dependencies [V1]
      6.1  Data files [V1]
      6.2  Computed Lisp files [V2]
      6.3  Tests [V2]
      6.4  Crypto Check [V3]
      6.5  Template Instantiations [V5]
    7   Internals [V4]
      7.1  Error handling [V4]
    8   Higher-level description [V1]
      8.1  XCVB's Architecture
      8.2  Grains and Types
        8.2.1  Initial, Final and in-between
        8.2.2  Persistent vs Transient
        8.2.3  Intention vs Extension
        8.2.4  Generated modules
      8.3  Plans
        8.3.1  Build Graph
        8.3.2  Computations
        8.3.3  Actionable operations
        8.3.4  Complete plan
        8.3.5  Plan transformation
        8.3.6  Reference model
        8.3.7  Dependencies
      8.4  Operators
        8.4.1  Abstracting Operations
        8.4.2  Generating computation and hashes
        8.4.3  Graph building
    9   Advanced Build Issues [V3]
      9.1   Read the classics [V3]
      9.2   distclc [V3]
      9.3   clcache [V3]
      9.4   XCVB as its own backend [V3]
      9.5   Push for better control of file source location [V3]
      9.6   Push for better control of in-file source location [V4]
      9.7   Push for more determinism in Lisp compilers [V5]
      9.8   Push for First-class PCLSRing in Lisp compilers [V5]
      9.9   Support dependencies for modules written in other languages [V4]
      9.10  Mixing and Matching compilers [V5]
      9.11  Constraint-based goal language [V6]
    10  A Real Module System [V3]
      10.1  Syntax Extensions [V3]
      10.2  Automatic Package management [V5]
      10.3  Better Namespace Management [V5]
      10.4  Hooks into the Module Naming Resolution [V5]
      10.5  Packaging and Distribution [V5]
      10.6  More bibliography [V5]


Current Developments
====================

A complete rewrite is underway.
We've got a static backend that creates a graph.
We most urgently need to:

 * Make the Makefile backend fully functional:

    * create object directories as required (log from makefile, add a target)

    * create a one initial image that has ASDF and XCVB-DRIVER loaded?
      For the sake ASDF, we need a setup file.
      Defaults in:
        * ./target-image-setup.lisp
      	* ~/.config/xcvb/target-image-setup.lisp
        * $PREFIX_ETC/xcvb/target-image-setup.lisp

 * When we've surpassed the v0.1-prototype, create another branch,
   and announce a new preview edition.

 * Update the migration code from ASDF.
   Support recursive migration of dependencies up to some point that the user may specify
   (i.e. for every transitive asdf system dependency, stopping at given ones, migrate system).

 * Support BUILDs that actually override given ASDFs, for incremental migration.
   Optionally issue a warning when a BUILD depends on an ASDF that has (later) been migrated.

 * Re-implement ASDF backend, so ASDF users can use XCVB BUILDs.

 * Add support for arbitrary shell commands.

 * Add some support for generated Lisp files.

 * Apply XCVB to some actual big projects at ITA.

 * Revise documentation, including this very file.


Roadmap [V1]
============

Improvements required for XCVB version 1 are marked [V1].
These correspond to a system suitable to automatically replace ASDF,
but otherwise without any extra feature besides
the enhanced robustness, maintainability and integration with ``make``.

Improvements required for XCVB version 2 are marked [V2].
These correspond to the "V" in XCVB: Verification.
Automated incremental testing, dependency groveling,
checksum verification, compartmentalized file trees, etc.

Improvements required for XCVB version 3 are marked [V3].
The goal is for XCVB to be able to build Lisp projects
all by itself, taking advantage of parallelism and distribution,
minimizing slow LOADs by forking (or dumping images?), etc.

Improvements required for XCVB version 4 are marked [V4].
The goal is for XCVB to become its own better building system,
able to build arbitrary Lisp or non-Lisp projects in a robust way,
with a distributed farm of machines able to identify objects
by a cryptographic checksum of
the precise source and compilation options used.

Improvements required for XCVB version 5 are marked [V5].
The goal is for XCVB to grow fancy features and heuristics
that demonstrate the advantages of a higher-level design.
Things go here that have really low priority.

As things get done, they should be moved
from the ``TODO`` document to the appropriate documentation
(at this moment, either ``README`` or ``INTERNALS``).


Usability Issues [V1]
=====================

This section describes usability bugs,
i.e. things that do not modify the deep semantic model of XCVB,
but are necessary to make it usable.


Lack of Manual [V1]
-------------------

Document all there is to know to use XCVB in README.rest.
If README grows too big, create a separate MANUAL.rest.

There should be both a tutorial and an API specification.


Migration from ASDF [V1]
------------------------

We can already do simple cases. See ``doc/exscribe-migration.lisp.example``.

We need to handle more complex cases involving migrating
several ASDF systems to XCVB,
or systems that rely on ASDF extensions such as
compile-time reading of data files or
dynamic creation of lisp files.

Ideally, you should be able to simultaneously convert many systems at once,
while deciding which systems will preserve their identity,
which will be merged, etc.
Or you should be able to convert systems incrementally,
and have the converter autodetect that some ASDF dependencies
have already been converted into XCVB dependencies.
i.e. the system should be able to scan existing XCVB builds in a search path
and maintain a table of which ASDF systems
have been superseded by which available BUILD.


Configurability of the build image [V1]
---------------------------------------

The user needs to be able to specify files to be loaded
and/or forms to be evaluated in the initial build image.
Most notably he needs to be able to customize his ``asdf:*central-registry*``
and possibly proclaim the desired optimization settings.

Typically, this is done by a file called setup.lisp
loaded into the initial staged build image.

For a simple example, see ``doc/exscribe-compilation.lisp.example``.

It's there already, but we need to document how this works.


In-image loading [V1]
---------------------

Provide support for XCVB to be able to handle
compiling and loading a system into the given lisp image
(instead of relying on a generated ``Makefile`` or ``*.asd`` file --
or possibly by using either as a backend).

Note that this is also necessary for extensions to XCVB itself,
whereby extensions are to be loaded in the current XCVB image.
See the ``:load-into-xcvb`` extension (rename it!).

As a crock, we may use the ASDF backend to provide this feature.
Or we may just run-command a make, then unconditionally load
all the dependencies for the required module.
Or keep a hash-table of which modules have been loaded
(with which content cryptohash).


ASDF backend [V1]
-----------------

It is understood that ASDF can never fully implement
all the features required for XCVB.
Nevertheless, we should in most cases be able to do
a good enough job that with some additional discipline,
a correct XCVB module should build with ASDF as a backend.

Add support for ``:load-source`` dependencies.

Add a test suite for the ASDF backend.


Conditional Build [V1]
----------------------

XCVB needs to be able to handle conditional compilation of some files.

A simple way to do it, that we should support for [V1]
would be to use conditional reading with #+ and #-
like people currently do with ASDF.
Because the builder and buildee are separate, this means that
XCVB must somehow extract the features of the buildee
(by running the target lisp) before it reads any of the files.

However, that approach is a hack that doesn't scale to larger builds
where the same file would be compiled many times using different compilers
and feature sets.
At some point before [V3], we'll want to have a specialized language
to specify conditional dependencies.
mudballs has something that we should look into.


Generalized Staged Images [V2]
------------------------------

Instead of ad-hoc bootstrap images, provide a general mechanism
for building images used to build further images,
and use it for the initial image.


Command-line interface [V3]
---------------------------

It should be possible to invoke and control XCVB fully from the shell command line
(and/or from a carefully constructed ``Makefile``)
without the user having to edit a Lisp configuration file.
The XCVB command-line should obey the usual unix command interpreter syntax::

	xcvb {xcvb-options} {script {script-arguments}}

The command-line should allow to express all the common usage patterns.
These patterns will be discovered as we build V1 and V2.


Features [V1]
=============

This section describes features that have to be added to XCVB.
They modify the underlying build model.


Multiple BUILD.lisp files [V1]
------------------------------

Allow the build-requires slot to work with multiple BUILD.lisp files.
Right now, only the top-most BUILD.lisp file's build-requires slot
is properly handled, the rest are ignored.

To add this functionality, the makefile-generator will need to write
a makefile that dumps multiple intermediate cores
-- one for each BUILD.lisp's build-requires slot (if present) --
and also has multiple ${CWBRLRUN} macros
so that compilation will happen with the correct core at each step of the way.
The asd-generator will similarly need to be changed
to have one asdf module for each BUILD.lisp's build-requires slot (if present).


Improve Makefile backend [V2]
-----------------------------

Create and document the following small features:

  * give user control as to where generated objects go vs source code.

  * use Makefile variables as path prefix for most everything?

  * use a map file that maps virtual names to path locations?
    This will be required in a distributed build, anyway!
    Use logical pathnames for that! Logical host XSRC: ?
    But then, we might need to include parts of portablish-pathnames
    with the driver...


Abstract Away Paths [V2]
------------------------

Have a datastructure for "string with substituted variables" (or shell or Make function calls?).

Be able to either dump a corresponding string (for writing Makefile),
or to expand into an actual string (for running the build).

Map actual paths to and from variablized strings, i.e. have
``${FOO}/bar/${GAH}`` in your path; it will search for files there,
and output ``${FOO}/bar/${GAH}/xcvb/BUILD.lisp``
in the ``Makefile`` (instead of the full expansion).


Initialization and Finalization [V2]
------------------------------------

Some code has to be run before and after file is compiled.

Before to compile a file, one may want to

  * change the readtable (or the reader)
  * set up some infrastructure (db connection)
  * initialize some meta-data tables

At the beginning of a file's compilation, one may want to

  * Insert compile-time or load-time form to be evaluated
    to dynamically initialize the module.

At the end of a file's compilation, one may want to

  * Insert compile-time or load-time form to be evaluated
    to dynamically finalize the module.

After the file is compiled, one may want to

  * save cross-reference data
  * register dynamic dependencies (i.e. "requires once-per-project instantiation of this form")
  * more generally update meta-data


Executables [V2]
----------------

When creating a standalone executable, some initializers and finalizers may have to be run as above.

If the executable needs a wrapping script, things get even trickier.

We may want to reuse cl-launch here, to leverage all the support already available.


Tests [V2]
----------

Test modules should be run when their dependencies have changed;
i.e. after they have been compiled into a FASL,
they should be loaded and create a report of whether the run was successful.
Reports can further be collected for statistics, etc.


Dependency grovelling [V2]
--------------------------

We may want to document how to extend asdf-dependency-grovel
when migrating systems from ASDF.

Actually, we might be interested in tweaking asdf-dependency-grovel
into some kind of xcvb-dependency-grovel
and possibly move all the groveling on the XCVB side,
taking a simple ASDF assumedly working serial compile-and-load plan
as the initial dependency map.

An XCVB dependency checker can detect unnecessary dependencies,
optionally remove them automatically.
With the help of some registry, it may even suggest
which missing dependencies should be added
-- and optionally automatically recompile after adding them.

For bonus points [V3], the groveler should know how to distinguish
between ``:compile-toplevel`` and ``:load-toplevel`` side-effects to
the evaluation environment.


Revert [V2]
-----------

We want a function to easily revert
the changes made by the ASDF to XCVB conversion,
so we may more easily clean up and experiment.


Bootstrap [V3]
--------------

We may want to fully migrate all the existing Lisp world,
*including* XCVB, from ASDF to XCVB.

The hardest part may well be extending and migrating asdf-dependency-grovel
(see above), but it may well be worth it.

We will want to have some non-invasive incremental strategy
to migrating all the existing ASDF projects,
and to integrate with some existing distribution mechanism
(clbuild or mudballs).


Same source, multiple compilers [V4]
------------------------------------

We will want to combine as part of the same build multiple compilations
of the same source files using different compilers and/or compiler options.

For instance, we may compile some source optimized for speed,
and the same source with extra safety features and code coverage instrumentation.
The code coverage version would be used in tests that identify
which parts of the test suite exert which part of the code,
and the results can drive future incremental testing of the test suite.
Meanwhile, the speedy version also runs the test suite,
just to make sure the optimizations don't break anything,
and it also is made to pass a performance tests
that aren't relevant to the slow version.

Another use for multiple compiler options is
when compiling the same source for use in different contexts,
such as one that is optimized for speed with default CL promises
(i.e. no guaranteed proper tail calls),
whereas the other one guarantees proper tail calls,
maybe provides call/cc (and supports interoperability with programs that do use it),
maybe even provides serialization of continuations, etc.
The more options you support,
the higher the burden on the compiler to produce good code,
but the wider the settings in which your code might be useful.
A very same executable could thus contain multiple versions of a same function
compiled with different options, to be used in different contexts.


Correctly handling C libraries [V4]
-----------------------------------

While objects may have to be compiled one way to be dynamically loaded into Lisp,
they may have to be compiled another way to be statically linked into the Lisp image.
XCVB will eventually have to know both ways, and do the right thing.

For dynamic objects, it should be able to have them installed in a place that
the Lisp image can find them when it needs them later.

For static objects, it should be able to recompile the Lisp runtime to include them.
This will require some synchronization with CFFI.


Dynamic compilation [V4]
------------------------

XCVB should have a thin layer that enables to call it from an interactive environment,
and request the loading of some system.

The thin layer will collect the information about the running system
and about objects already loaded in it, as well as the additional systems required,
then invoke (with fork+exec) an XCVB process that will build any additional file
and print a form to be evaluated by the calling process so it may be suitably enhanced.


Bug hunting [V5]
----------------

XCVB should be able to track down all the source files
involved in a test and point the blame to all those changesets
in the version control system that affected said files,
barring other changesets.
Actually, this information can be used to accelerate binary search
in a bissect-based bug hunt.
In such a hunt, some components would be fetched from version control
and others be otherwise cast in stone or computed --
which is particularly useful when the test was written
after the bug was found rather than the bug being a regression,
or when several bugs were introduced in a series of changesets,
some of which having been found and fixed bug not others.


Ideas from jknight
==================

Ideas from discussion w/ jknight:

 * allow python-like hierarchical installation paths instead of named BUILD.lisp
   (Isn't that already possible? Just have a top-level BUILD.lisp fullname'd "/" somewhere!)
   (The point was probably that we can avoid eager search if only we can agree on
   some naming hierarchy for both "module names" and filesystem relative paths.)

 * allow pre-built installation paths that are self-describing enough to make it work.

 * extending XCVB: allow people to export a procedural interface as in "rebuild me"
   rather than only a declarative interface "conform to my crazy internal graph representation".

 * Makefile already doesn't like spaces in names (except implicit names from current path).

 * allow xcvb.mk to be usable without XCVB.

 * --object-directory=object option

 * autotools: the output goes into the directory it is run from by default.

 * option to only create relative pathnames

 * do away with all calls to truename?


The semantics of dependencies [V1]
==================================

Data files [V1]
---------------

Allow a module to depend on an auxiliary data file.
That file will not be compiled or loaded into the Lisp image,
but will just be used for tracking
when the file that depends on it needs to be recompiled.


Computed Lisp files [V2]
------------------------

Allow source files to be dynamically computed,
including the computation of its dependencies.

For the Make backend, this means that ``xcvb`` and ``make``
shall be called recursively called by the rule for the object target
after the Lisp file has been created.

For the independent backend, this means that the dependency graph
can grow new nodes and arcs as some files are discovered.


Tests [V2]
----------

XCVB should also have an interface to specially run (or skip) tests.

Tests don't just output a summary,
they also have a status that affects the build.
For instance a test that runs to completion
and successfully creates a valid report
may detect issues that flag the build as a whole as invalid.

XCVB should be able to thus synthesize and associate diagnostics to the overall built.


Crypto Check [V3]
-----------------

An important precondition to deterministic compilation is that
input files should not be modified in the middle of a compilation run.
XCVB should have a safe mode (enabled by default)
to check the cryptographic checksums at the beginning and end
of each transaction, and abort the transaction removing dubious object files
if anything has changed between the beginning and end of a command.

Here, transaction means anything that commits any object file to cache,
any metadata to some registry, etc.

For instance, if you're compiling file foo.lisp that depends on bar.lisp
to create foo.fasl and foo.cfasl, with some additional code coverage instrumentation,
and dependency detection that gets registered in a side cache,
then record the checksums of foo.lisp and bar.lisp before you compile,
double check that they didn't change afterwards, if they did,
then remove foo.fasl and omit to update the cache.
The check before running a command may or may not be omitted
if the file has already been checksummed during the current run,
the previous checksum being used;
or the checksum may be eagerly re-checked at every command.
In either case, it should always be checked after the command.

If checking checksum at every command is too time consuming, then there is the option
of only doing it at the beginning and end of the overall compilation,
but then any update of global caches should have the same granularity.
For a distributed build, definitely check before and after every command.


Template Instantiations [V5]
----------------------------

One interesting type of dependencies is template instantiation.
Some libraries may provide a family of algorithms
that are parametrized by various types or values,
the semantics of the algorithm being fully encapsulated
in the data of the library and the instantiation parameters.
The template for these algorithms must be instantiated
for a given set of parameters before it may be used,
yet this instantiation is costly enough in time and/or memory
that you want it to be done only once over the whole project.

We'll want XCVB to be able to track down such template instantiations.
One way of course is to have the user do it manually,
with one of the declared dependencies of a module being
something that instantiates the library.
This works if such templated libraries are few and far between.
Another way that scales to massive use of such libraries
is that the compilation process would automatically detect
the need for such instantiations,
and include them as additional project dependencies
as the need for such appears.


Internals [V4]
==============

Error handling [V4]
-------------------

We should refactor all error throwing with a call to simply-error,
using a condition defined specifically for that error.

We should also provide a nicer way of presenting errors to the end-user.
Maybe there should also be some library for that.



Higher-level description [V1]
=============================

This should be cleaned up and moved to
the INTERNALS.rest document at some point.


XCVB's Architecture
-------------------

It's OK that we started with hand-coding the behaviour of XCVB in Lisp
but eventually, we should have a domain-specific language to describe
the structure of the dependency graph and the operations used to build it.

For XCVB version 1, we want to cleanup the internals.

For XCVB version 2, we want to have a sensible basic design
for arbitrary Lisp code.

For XCVB version 4, we want to have a fully generalized design
that can handle arbitrary operations used to build projects
using any kind of programming language or compiler, not just Lisp.

For the sake of avoiding ambiguity and starting from existing knowledge,
we'll try to reuse the vocabulary defined in MIT AITR-874
to describe the concepts at hand.


Grains and Types
----------------

*Grains* are the units of data that the build deals with.

Grains come in many *types*
themselves hierarchically organized in subtypes and supertypes.
Main types include files and running processes;
subtypes of files include Lisp source files, C source and header files,
shell scripts, python scripts or perl scripts,
ReST documents, FASL files (that come in as many variants
as there are combinations of Lisp implementations and various options),
linker object files (for many architectures),
executable files (for as many architectures),
test report files, etc.
Types of processes include Lisp compilation processes,
C compilation processes, etc.


Initial, Final and in-between
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Some grains are the inputs of the overall build, they are the *initial* grains.
They include the *source* code and data
(usually kept under revision control and otherwise part of the source archive),
user-specified *configuration* (edited by users to fit their local configuration),
and any file (such as a compiler) or process (some daemon) in the running *environment*
that is used during the build.
Anything else is a *derived* grain.

Some grains are the outputs of the overall build, they are the *final* grains.
They are anything sought for by the user,
usually deliverable files needed for some software installation.

Some grains may be both initial and final,
for instance data files that are copied over as is
from the source archive to the final installation.
Some grains are neither initial nor final, they are called *intermediate* grains,
and are usually thrown away after the build.

For *bootstrapping* purposes, the content of a final grain
is sometimes copied into what will be a source grain in future sessions.
Within a given build session, though, we will distinguish
the initial grain
(that may be the copy of a final grain from a previous session)
from the final grian
(that may be copied as an initial grain for a next session).


Persistent vs Transient
^^^^^^^^^^^^^^^^^^^^^^^

Files are *persistent* grains. They are stored on disk.
They can be trusted to be recovered from one session to the next.
They cannot spontaneously compute.

Processes are *transient* grains. They do the computations.
They can transform inputs into outputs, and in between maintain active state.
They often are born and die within a session,
and may not be trusted to survive until a next session
(although if the build is used to monitoring updates to a live robust system,
they may well be).


Intention vs Extension
^^^^^^^^^^^^^^^^^^^^^^

We must distinguish file path from file contents,
process id and process state.

File *contents* are pure extensional data,
while file *paths* are intentional anchors.
Similarly, running *processes* are the intentional agents,
whereas *process states* are the extensional states.

In a given *session*,
the mapping of source path (intention) to contents (extension)
is assumed to not change.
Otherwise, an error condition is detected,
and the build may be aborted or restarted as a new session.
In a given session,
it may thus be assumed that a file behaves
like persistent pure functional data,
deterministically yielding the same contents every time it is read.

On the other hand,
the mapping from processes (intention) to process states (extension)
is likely to change a lot during a session
(and a fortiori between sessions).
The computation that happens in a given process consumes
its input state that is lost as it produce its output state.
Process state is thus behaves like a linear pure functional data.
Processes may be created with an birth state,
or die and cease to have a state.

Process state is often considered up to some gross equivalence
that neglects details such as process id, etc.
If you may neglect a small driver that forks the processes
and executes requested tasks,
or dumps images and resumes from them,
then you may be able to explicitly duplicate the state of a running process.
So as to be able to reinstate a desired state
on another machine or in another session,
the build needs to be able to reconstruct such state
from persistent data (e.g. by dumping an image),
up to the desired equivalence.


Generated modules
^^^^^^^^^^^^^^^^^

Generated modules count as derived grains, not source,
since they need not be part of the source archive
and are not checked in to revision control system
(unless they are indeed bootstrapped,
in which case the derived final file of a build
may be initial source file for the next).

They may make the build more complex in that
the build needs to know the associated dependencies
before it may plan how to build the derived grains,
yet may not be able to know these dependencies
before the Lisp file is generated.

In simple cases, the dependencies can be identified
before the file is generated,
as special off-file declarations in the generating source code.

In other cases, the build system may have to update
its build graph after the file is computed,
possibly doing a recursive call to the main build entry point.


Plans
-----

Build Graph
^^^^^^^^^^^

The plan is a build graph
that contains nodes that represent the intensional grains,
and nodes that represent the intensional operations
that will derive output grains from input grains,
from the initial ones up to the final ones.

As the builder executes the plan,
it computes the extensions of derived grains
from the extensions of former grains.

At the beginning of a session,
only the initial extensions are available.
At the end of a session,
the final extensions are computed.

The plan is static if it doesn't need to be updated
based on the extension of any derived grain.
The plan is dynamic if it new nodes need to be created
during a given session.


Computations
^^^^^^^^^^^^

Computations are nodes in the build graph,
that join together a set of input grains to a set of the output grains.

A computation node represents an actual computation whereby the output grains
can be computed from the input grains when the latter are available.

The computation may involve creating processes or talking to existing processes;
these processes will change state, including being born and dying,
as they run the specified commands,
creating output grains as they consume input grains.

For caching purposes, a computation also specifies how to compute a buildhash
identifying each of the outputs of the operation
from the buildhashes of inputs.


Actionable operations
^^^^^^^^^^^^^^^^^^^^^

In a given backend (i.e. ``Makefile``, ASDF, etc.),
not all operations are permitted.
For instance with make, you can't duplicate a process state with fork,
whereas you could with a future native backend.
Additionally, some Lisp compilers have operations that other compilers don't.
For instance, you can't load then dump --
instead you link with a special process.
An operation that can actually be executed is called *actionable*.

And so whether operations are decomposed into basic elements
or grouped in actionable wholes depends on the specific target.
Also, multiple operations may lead to the "same" outcome
up to the desired equivalence, and operations may be combined
in different ways.
Some combinations may be preferred to others,
especially if the some are valid operations on the target
whereas the others are not,
but also if some operations are reputedly slow
whereas others are expected to be fast.


Complete plan
^^^^^^^^^^^^^

In a complete plan, all operations are actionable.
Moreover, initial grains are never the output parameter of an operation,
and derived grains appear as the output parameter of an operation
exactly once in the build graph.


Plan transformation
^^^^^^^^^^^^^^^^^^^

From the module declarations, a model may be constructed
of which modules contain compile-time or load-time references
to which other modules,
and otherwise depends on which modules at build-time, etc.
This reference model constitutes a build graph,
but may not be an actionable build graph,
and may notably include intermediate grains
representing process states that may be not be reachable
in the specific target environment
that the build session will take place in.

Thus, the build system may have to transform its plan
both for the purpose of correctness and
for purpose of performance optimization.
A build session with start by computing the reference model
from the extension of the initial grains,
and from the build request,
then apply configuration-dependent transformations
to that plan to create a complete plan.


Reference model
^^^^^^^^^^^^^^^

We possibly may want to fully distinguish the reference model
as something distinct from a build graph, just like the AITR-874 author.
Then we could handle reference classes such as:

  * ``(:package-ref A B)`` - A uses a package defined in B (before to either compile or load A, load B).
  * ``(:macro-calls A B)`` - A uses a (reader)macro in B (before to compile A, load B).
  * ``(:calls A B)`` - code in A calls code in B (before you run code in A, load B).
  * ``(:setup-calls A B)`` - while loading A there are calls to code in B (load B before you load A).

Note that the current XCVB model of ``:depends``, ``:load-depends``, ``:compile-depends``
corresponds loosely to ``:package-ref``, ``:setup-calls``, ``:macro-calls``.
We may want to add a ``:run-depends`` to add the functionality of ``:calls``.


Dependencies
^^^^^^^^^^^^

The *declared* dependencies of a node
(or declared inputs of an operation)
are computed by the operator that creates the operation node,
and include all the grains that must be available
before the operation may be computed.
They are established at the beginning of the session
at the time the actionable plan is created,
and do not change for a static plan,
but may be updated for a dynamic plan,
in which case an operation that will update the dependencies
might itself be required as part of the plan
before the operation may be computed.

The *effective* dependencies of a node
(or effective inputs of an operation)
include any grains that were actually consulted in computing the operation.
In a static build, these effective dependencies
will be the same as the declared dependencies.
In a dynamic build, which dependencies were or weren't included
may sometimes be discovered only after the fact.
If they are found to contain grains that weren't available,
a condition is raised, and
the build session may be aborted,
or the required grains may be computed
before the operation may be restarted.

Note that when an object file itself hasn't changed as a result of a computation,
but one its dependencies (or the list of dependencies itself) has changed,
then one may have to recompile all files that depend on it.
This is taken into account by digesting not just the direct dependencies,
all the transitive dependencies loaded before the computation.
And so, if building a propagation network for recompilation,
the list of dependencies itself is to be part of
the network that triggers updates to a compilation,
not just the individual dependencies listed.


Operators
---------

Abstracting Operations
^^^^^^^^^^^^^^^^^^^^^^

*operators* are methods that create concrete operations
out of various parameters.

Parameters may include input grains, output grains,
options (which compiler/flags to use), etc.

Note however, that the inputs and outputs
of one of the operations created by an operator
need not be those given as parameter by the operator.
For instance, an operator may create intermediate grains,
add detected dependencies, recurse by calling other operators, etc.
(Operators correspond loosely to what AITR-874 calls
request-handlers and reference-handlers,
or to what ASDF calls operations).

A same grain can be used as the parameter to multiple operations,
or to the same operator in multiple instances with different other parameters.
For instance, a file may be both compiled
and processed for documentation extraction.
Or it may be compiled for speed in one case,
compiled for code coverage in another case,
and compiled with serializable continuations in a third case.


Generating computation and hashes
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The computation, the static buildhash,
and the algorithm to compute the dynamic buildhash
may all be obtained from the same specification
of the relationship between outputs and inputs,
at the time the operator is instantiated.

Say the operation has some specification like::

  (:compile-lisp :loading (fasl1 fasl2)
		 :source lisp3 :target fasl3
		 :lisp-compiler image4 :options (o5 o6 o7))

Then the evaluator would invoke the specified Lisp image
with the proper options to load the specified fasls
and compile the source file into the target fasl.

The direct hash of a grain would be a cryptographic hash of
its specification (type and module name)
followed by the hash of its file contents
(or for a process,
the hashes of the binary images and configuration files used
to start the daemon).

The static buildhash of each output grain
can be obtained in advance of any computation
with a cryptographic hash of the concatenation of the specification,
something that identifies which output is considered
(say ``"(1)"`` for the first output,
or ``"(2 3)"`` for the third file in the second list of outputs,
or just the output module name),
and the successive static buildhashes of each of the inputs,
with the static buildhash of an initial grain being its direct hash.

The dynamic buildhash of each output would be computed in a similar way
right before (for a static computation)
or right after (for a dynamic computation)
the computation, by hashing the concatenation of the specification,
of the output identifier, and the successive direct hashes
of each declared input (for a static build)
or effective input (for a dynamic build).

The hashing algorithm used for all hashing by XCVB will be
a Tiger Tree Hash (TTH).

Hashes can be used to index a cache of already computed objects.
Static builds with only static computations
may use the static buildhash to index objects in the cache
in advance of any computation --
and by looking for final objects directly at the top of the graph
skipping unneeded intermediate grains.
Dynamic builds or builds with dynamic computations
must use dynamic buildhash to index objects in the cache
and must rebuild all grains from the ground up.
Builds with both static and dynamic elements are conceivable.


Graph building
^^^^^^^^^^^^^^

A build starts with an initial request:
an operator is called with a set of input parameters.




Advanced Build Issues [V3]
==========================

Read the classics [V3]
----------------------

As we try to get XCVB to rival with existing build systems,
we may want to cover our bases and see what previous systems
did right and what they did wrong.

Rainer Joswig on #lisp suggested:
'BUILD: A tool for maintaining consistency in modular systems'
by Richard Elliot Robbins, 1985.
ftp://publications.ai.mit.edu/ai-publications/pdf/AITR-874.pdf
The build system described takes an interesting declarative approach:
the system builds an abstract model of the modules in terms
of grains having various kinds of directed reference relationships as
in (:macros-calls foo bar).
The task graph to fulfill a build request is automatically deduced
from the reference model and various request-handlers
(pre and post reference handling) and reference-handlers
that propagate the information along the nodes.

See also GNU Make, OMake, CMake, SCons, Boost Jam, Cabal, etc.:

	* http://www.scons.org/
	* http://omake.metaprl.org/index.html
	* http://www.cmake.org/

distclc [V3]
------------

The first step towards distributed builds is to plug into the usual ``Makefile``, etc.,
mechanisms, only adding an automated manager for distributed compilation through
a farm of available hosts, just like ``distcc`` does for C compilation.

``distclc`` should be written on top of Erlang-in-Lisp.


clcache [V3]
------------

The second step towards distributed builds is to have an automated
(distributed) cache of compiled objects, just like ``ccache`` does for C compilation.

Interestingly, to do it properly, we index grains by a buildhash
that summarizes all the input used to build the grain, including
type of the grain, command used, contents of the source files,
binaries used to run the compilation, etc.

To achieve that in a semi-automatic way, we may architect the operations
used to build grains in an I/O-summarizing monad that identifies then
summarizes inputs and outputs of the operations --
which monad can itself be decomposed in terms of input-identifying
and output-identifying monads, etc.
In a Haskell world, the monad would annotate the type of each
of the many intermediate functions involved.


XCVB as its own backend [V3]
----------------------------

Eventually, we want to be able to take over the Lisp build from Make,
so as to achieve things that Make can't do.

This can be done after we have ``distclc`` and ``clcache``,
by evolving the result to the point that we don't need Make.


Push for better control of file source location [V3]
----------------------------------------------------

When doing a distributed build,
of course the actual pathname of the file being compiled or loaded
will be different from the virtual name of the module being compiled or loaded.

For instance, when asking ``distclc`` to compile
module ``foo/bar/baz.lisp`` under directory ``/home/fare/src/``
which as a dependency loads ``quux.fasl``,
``distclc`` may actually create a temporary file
``12345.lisp`` where ``12345`` is the hash of ``baz.lisp``
under directory ``/tmp/distclc/``
and reuse ``67890.fasl`` from ``/var/cache/clcache/6/7/``
where ``67890`` is the hash of ``quux.fasl``.

Yet when associating source location information to functions being compiled,
XCVB needs be able to tell the underlying Lisp compiler that it should be
using the virtual location foo/bar/baz.lisp (and foo/bar/quux.lisp),
and additionally identify the hash of the file's contents
and possibly its revision in the version control system.

Of course, logical pathnames as defined by the CLHS are about unusable.
So offer to standardize something different for those virtual paths,
and the way that SLIME and/or the builtin debugger with interpret those paths.

jsnell suggests to look at what SLIME does -- presumably (for SBCL)
ask for extra information to be stored in the debug info with
a non-standard with-compilation-unit keyword. OR one might be able to do
sneaky stuff with logical-pathname-translations: ask to ``COMPILE-FILE``
some logical-pathname for which an ad-hoc translation was created.


Push for better control of in-file source location [V4]
-------------------------------------------------------

A related problem is in-file source location.

When using a syntactic front-end that generates Common Lisp code
from a different dialect or language
(say, a variant that supports hygienic macros,
or a Haskell to Lisp compiler),
the precise in-file location of a source statement that CL compiles
is not at all the same as the one that matters for the debugger
to location the actual source code.

For instance, one could provide hygienic macros through a form
``WITH-HYGIENIC-MACROS`` that does the necessary whole-program
identifier tracking. This would make a typical CL source location
tracker that only remembers the enclosing toplevel form wholly useless.

The PLT Scheme system has a good source tracking facility
that we may want to reuse of get inspiration from.
Even the C preprocessor has the crude line identification:
``# 123 "baz.h" 2 3 4``

For SBCL, ask jsnell, tcr, nyef: the preprocessed file could expand to
things like ``#.(preprocessed-form 345)`` where the ``(preprocessed-form ...)``
function would return expanded forms and subforms that each (as applicable)
already have source locations associated through something like::

  (setf (gethash EXPANDEDFORM *some-source-location-hash*)
        ORIGINAL-SOURCE-LOCATION)


Push for more determinism in Lisp compilers [V5]
------------------------------------------------

We should encourage implementers of Lisp compilers
to offer as an option (or even the default)
to have as much determinism as possible in the compile of files.

If to avoid collisions these compilers require that
a pseudo-random number generator be initialized to different values
for each file being compiled,
then offer to initialize it based on the buildhash
for the current compilation
(with an override to a previous buildhash offered for debugging purposes).

Try to standardize an interface to deterministically initialize the PRNGs
and deterministically add noise to them, based on arbitrary initial seed data.

Maybe also standardize some strong cryptographic hash algorithms
and algorithm generators for arbitrary Lisp data,
as are used by clcache.


Push for First-class PCLSRing in Lisp compilers [V5]
----------------------------------------------------

To support single-stepping and safe concurrency
in arbitrary extensions to the base language,
it may be crucial to push a meta-level protocol for first-class PCLSRing
whereby writers of language extensions and applications
can specify the atomicity of their operations
in a way that will be compiled efficiently,
yet will guarantee that synchronization happens correctly
when interrupting a program.


Support dependencies for modules written in other languages [V4]
----------------------------------------------------------------

If XCVB is to become a general build tool,
it needs to be made aware of dependencies for projects written in other languages.
This includes using output of ``gcc -MM``, and other dependency generators.


Mixing and Matching compilers [V5]
----------------------------------

A given project may contain files written in many languages,
including but not limited to Common Lisp and C.
Additionally, there may be various different variants of FFI
to be used to interface modules written in different languages,
depending on the specific compiler and compiler options used.

For instance, interfacing code compiled by a given Scheme compiler
with given options will differ from interfacing with the same
code compiled by a different compiler, or even with code compiled
by same compiler with different options.
Yet, for whatever reasons, a given project might want to mix and match
modules written in different languages.

XCVB might grow some generic protocol to describe the steps required to
interface something to something else.


Constraint-based goal language [V6]
-----------------------------------

The build language of XCVB could in the most general case be
some constraint declaration language, and XCVB would use a constraint solver,
whereby you want to build a running system that has these final properties,
starting from an existing running system that has these initial properties.
XCVB could detect conformance of the specification with various known subsets
of the language that keep the constraint satisfaction easy.


A Real Module System [V3]
=========================

Up to version 4, XCVB can be seen as the bottom half of a real module system.
But hopefully we can build a real full-fledged module system on top of XCVB,
including syntax extensions and namespace management.


Syntax Extensions [V3]
----------------------

Because modules are compiled in a separate way that shields them
from unwanted compile-time side-effects necessary to build other modules,
it immediately becomes possible for a module to have a compile-time dependency
on a module that modifies the syntax of Common-Lisp by introducing arbitrary
macros and reader-macros.

We may generalize this by having XCVB manage an explicit override of the reader
used to compile a given module.

To preserve debuggability, this requires extension to existing compilers
so they provide better control of in-file source location [V4].


Automatic Package management [V5]
---------------------------------

Defpackage statements are a notorious pain to maintain in Lisp.
At the same time they need to be all setup in advance of the rest of the compilation.

A layer on top of XCVB could help manage packages dynamically,
by allowing to associate a package with a module, itself made of many submodules.
An initial simple ``defpackage`` form would be supplied by the user;
what the module actually ``export``'s (or even ``import``'s) could be dynamically inferred
from the compilation of the module (and all its submodules),
with the final ``defpackage`` being created automatically from this inferrence.

Recompilation might be required if the ``defpackage``'s imports have changed
since it was last inferred, or it could just be an error.

All users of the module would only see the final stable ``defpackage``,
and have to be recompiled when said ``defpackage`` changes.

Finally, this could serve as the basis for dumping
package-based partial heap dumps with ``SB-HEAPDUMP``
instead of using FASLs.


Better Namespace Management [V5]
--------------------------------

Packages are not the be-all end-all of namespace management.
Actually, they are a very midesigned antiquated hack from the 1970's
that has long overlived its expiry date.
Many much better namespace management systems have been created
since the 1980's for many Lisp dialects and other languages.
Even for Common-Lisp, cheap yet better replacement exists, Lexicons.

We may want to layer on top of XCVB
an syntactic extension to Common Lisp that properly handles namespaces.

For instance, we might reuse concepts and even code from the PLT Scheme system,
both regarding their module system and their unit system.
A key to doing it properly is to have already solved the syntax extension issues
and the macro hygiene problem (see above).
But we can decouple the source-level debugging issue as an addendum to the
the being able to do it at all issue.

Don't miss this important bibliography:
  http://readscheme.org/modules/

Taylor Campbell on the irc.openprojects.net ``#scheme`` channel gave the following piece of advice.
Personally I think that it would be easiest to use Scheme48's module system for that,
but what I'd care most about is
(1) that you separate phases sensibly, and
(2) that you provide working hygiene.
See Flatt, 'Composable and Compilable Macros', 2002.
http://www.cs.utah.edu/plt/publications/macromod.pdf
(The R6RS's library system emphatically got phase separation wrong.
Don't repeat their mistake.)


Hooks into the Module Naming Resolution [V5]
--------------------------------------------

So as to support compilation of a project that spans over multiple BUILDs,
a module naming system was implemented.

When a module is not found, a hook function may be called,
that allows for arbitrary computed modules, most notably including
modules automatically downloaded and installed on demand from the internet.


Packaging and Distribution [V5]
-------------------------------

At some point, we may want to extend XCVB to handle
the automatic packaging and distribution of Lisp-based projects.

See ASDF-INSTALL, clbuild, mudballs, etc.

See Haskell Cabal and Hackage, Caml Hump,
Ruby gems, Python eggs, Chicken eggs, Java beans, etc.

When extending the system to include the management of packages for distribution,
be sure that you play well with whichever Operating System's packaging software:
http://www.b-list.org/weblog/2008/dec/14/packaging/


More bibliography [V5]
----------------------

http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=138664
